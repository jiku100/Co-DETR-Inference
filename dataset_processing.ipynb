{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['info', 'categories', 'images', 'annotations'])\n",
      "277\n",
      "{'id': 1665702843794501, 'height': 1080, 'width': 1920, 'url': 'manifold://ego_objects_v1/tree/images_and_annotations/images/00ED3B9E9100528CCFDCB958B489A3BD_01_25.jpg', 'gaia_id': 334937101979014, 'timestamp': [1645099834.815261], 'stream_ids': ['1201-2'], 'group_id': '00ED3B9E9100528CCFDCB958B489A3BD', 'video_id': '01', 'frame_id': 25, 'main_category': 'Banana', 'main_category_instance_ids': [1]}\n",
      "{'id': 1, 'image_id': 1665702843794501, 'bbox': [752.29, 527.23, 371.66, 307.4], 'category_id': 22, 'instance_id': '00ED3B9E9100528CCFDCB958B489A3BD_22_0', 'area': 114248.284}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open(os.path.join(root_path, \"new_train.json\")) as f:\n",
    "    train_data = json.load(f)\n",
    "print(train_data.keys())\n",
    "print(len(train_data[\"categories\"]))\n",
    "print(train_data['images'][0])\n",
    "print(train_data['annotations'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def category_names_to_snake_case(category_name: str) -> str:\n",
    "    \"\"\"Convert category name to snake case.\n",
    "\n",
    "    Args:\n",
    "        category_name (str): Category name in string\n",
    "\n",
    "    Returns:\n",
    "        str: Modified category name.\n",
    "    \"\"\"    \n",
    "    return (\n",
    "        category_name.lower()\n",
    "        .replace(\" \", \"_\")\n",
    "        .replace(\"/\", \"_\")\n",
    "        .replace(\"(\", \"\")\n",
    "        .replace(\")\", \"\")\n",
    "        .replace(\"&\", \"and\")\n",
    "        .replace(\"-\", \"_\")\n",
    "    )\n",
    "\n",
    "def xulyulwh_to_clipped_xcycwh(xulyulwh: list[float], width: int, height: int) -> list[float]:\n",
    "    \"\"\"Convert bounding box format and clip it to image boundary.\n",
    "    Input format is [x, y, w, h] where x, y is the top-left corner of the box.\n",
    "    Output format is [xc, yc, w, h] where xc, yc is the center of the box.\n",
    "    All four vertices of the box are clipped to the image boundary.\n",
    "\n",
    "    Args:\n",
    "        xulyulwh (list[float]): Input bounding box in [x, y, w, h] format.\n",
    "        width (int): Image width.\n",
    "        height (int): Image height.\n",
    "\n",
    "    Raises:\n",
    "        Exception: The bounding box is outside the image boundary.\n",
    "\n",
    "    Returns:\n",
    "        list[float]: Bounding box in [xc, yc, w, h] format.\n",
    "    \"\"\"\n",
    "    x, y, w, h = xulyulwh\n",
    "    if x < 0:\n",
    "        w += x\n",
    "        x = 0\n",
    "        if w <= 0:\n",
    "            raise Exception(\"Invalid box\")\n",
    "    if y < 0:\n",
    "        h += y\n",
    "        y = 0\n",
    "        if h <= 0:\n",
    "            raise Exception(\"Invalid box\")\n",
    "    if x + w > width:\n",
    "        w = width - x\n",
    "        if w <= 0:\n",
    "            raise Exception(\"Invalid box\")\n",
    "    if y + h > height:\n",
    "        h = height - y\n",
    "        if h <= 0:\n",
    "            raise Exception(\"Invalid box\")\n",
    "    return [x + w / 2, y + h / 2, w, h]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "from typing import Sequence\n",
    "from statistics import mean, stdev\n",
    "import ujson as json\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class DetectionDataset(ABC):\n",
    "    \"\"\"Format of a detection dataset.\n",
    "    Category dictionary should have the following keys:\n",
    "        'category_id' (int): Unique identifier for the category.\n",
    "        'category' (str): Name of the category.\n",
    "        '{split}_instance_count' (int): Number of instances in the {split}.\n",
    "        '{split}_annotation_count' (int): Number of annotations in the {split}.\n",
    "        '{split}_area_mean' (float): Mean area of the instances in the {split}.\n",
    "        '{split}_area_stdev' (float): Standard deviation of the area of the instances in the {split}.\n",
    "        '{split}_area_ratio_mean' (float): Mean area ratio of the instances in the {split}.\n",
    "        '{split}_area_ratio_stdev' (float): Standard deviation of the area ratio of the instances in the {split}.\n",
    "\n",
    "    Image dictionary should have the following keys:\n",
    "        'img_id' (int): Unique identifier for the image.\n",
    "        'url' (str): Absolute path to the actual image file.\n",
    "        'width' (int): Width of the image.\n",
    "        'height' (int): Height of the image.\n",
    "        'annotation_ids' (list[int]): List of annotation ids.\n",
    "        'split' (str): Split of the dataset (i.e., 'train', 'val', and 'test').\n",
    "\n",
    "    Annotation dictionary should have the following keys:\n",
    "        \"annotation_id\" (int): Unique identifier for the annotation.\n",
    "        'category_id' (int): Category id of the annotation.\n",
    "        'img_id' (int): Unique identifier for the image.\n",
    "        'bbox' (list[float]): Bounding box of the annotation in [x, y, w, h] format.\n",
    "        'area' (float): Area of the annotation.\n",
    "        'area_ratio' (float): Area ratio of the annotation to the image.\n",
    "\n",
    "    Attributes:\n",
    "        categories (dict[int, dict]): Dictionary of category id to category dictionary.\n",
    "        imgs (dict[int, dict]): Image data in the dataset.\n",
    "            The key is img_id and the value is an image dictionary described above.\n",
    "        annotations (dict[int, dict]): Annotations in the dataset.\n",
    "        imgid_orders (dict[str, list[int]]): Ordered image ids per each split.\n",
    "    \"\"\"\n",
    "\n",
    "    categories: dict[int, dict]\n",
    "    imgs: dict[int, dict]\n",
    "    annotations: dict[int, dict]\n",
    "    imgid_orders: dict[str, list[int]]\n",
    "\n",
    "    def group_imgids_by_key(self, key: str) -> dict[str, list[int]]:\n",
    "        \"\"\"Group the imgids based on the key string of img dictionary.\n",
    "\n",
    "        Returns:\n",
    "            dict[str, list[int]]: Key to list of imgids mapping.\n",
    "        \"\"\"\n",
    "        key_imgs = defaultdict(list)\n",
    "        for imgid, img in self.imgs.items():\n",
    "            key_imgs[img[key]].append(imgid)\n",
    "        return dict(key_imgs)\n",
    "\n",
    "    def get_catid_split_imgids(self) -> dict[int, dict[str, list[int]]]:\n",
    "        \"\"\"Get the mapping of category id to split and image ids.\n",
    "\n",
    "        Returns:\n",
    "            dict[int, dict[str, list[int]]]: Category id to split and image ids mapping.\n",
    "        \"\"\"\n",
    "        split_imgids = self.group_imgids_by_key(\"split\")\n",
    "        catid_split_imgids = {\n",
    "            catid: {split: [] for split in split_imgids.keys()}\n",
    "            for catid in self.categories.keys()\n",
    "        }\n",
    "        for split, imgids in split_imgids.items():\n",
    "            for imgid in imgids:\n",
    "                img = self.imgs[imgid]\n",
    "                for annotation_id in img[\"annotation_ids\"]:\n",
    "                    catid = self.annotations[annotation_id][\"category_id\"]\n",
    "                    catid_split_imgids[catid][split].append(imgid)\n",
    "        return catid_split_imgids\n",
    "\n",
    "    def create_ut_annotations(\n",
    "        self,\n",
    "        target_categories: Sequence[int | str],\n",
    "        annotation_root: str | Path,\n",
    "        stratify: bool = False,\n",
    "        seed: int = 22,\n",
    "    ) -> None:\n",
    "        \"\"\"Create ultralytics detection annotations from the dataset.\n",
    "        Detailed format of the ultralytics detection annotation can be found here:\n",
    "            https://docs.ultralytics.com/datasets/detect/\n",
    "        The numberings of the categories in the ultralytics annotation will be based on the order of the target_categories.\n",
    "\n",
    "        Args:\n",
    "            target_categories (Sequence[int | str]): Annotation target categories. Both category id and category name are acceptable.\n",
    "            annotation_root (str | Path): Root to create the annotation directory.\n",
    "            stratify (bool): Whether to stratify the number of images per category in the training set.\n",
    "            seed (int): Random seed for stratification.\n",
    "\n",
    "        Raises:\n",
    "            Exception: target_categories contain invalid element.\n",
    "            NoInstanceException: No instance for the target categories.\n",
    "        \"\"\"\n",
    "        assert len(target_categories) > 0\n",
    "        category_catid = {\n",
    "            category[\"category\"]: catid for catid, category in self.categories.items()\n",
    "        }\n",
    "        target_catids = [\n",
    "            category if isinstance(category, int) else category_catid[category]\n",
    "            for category in target_categories\n",
    "        ]\n",
    "        annotation_root = (\n",
    "            Path(annotation_root)\n",
    "            if not isinstance(annotation_root, Path)\n",
    "            else annotation_root\n",
    "        )\n",
    "        image_dir = annotation_root / \"images\"\n",
    "        label_dir = annotation_root / \"labels\"\n",
    "        catid_split_imgids = self.get_catid_split_imgids()\n",
    "\n",
    "        split_imgids = {\n",
    "            split: set() for split in catid_split_imgids[target_catids[0]].keys()\n",
    "        }\n",
    "\n",
    "        cat_split_imgids = {\n",
    "            catid: {split: set() for split in split_imgids.keys()}\n",
    "            for catid in target_catids\n",
    "        }\n",
    "        min_train_count = 999999999999999999999999999999999999999999\n",
    "\n",
    "        for catid in target_catids:\n",
    "            if not isinstance(catid, int):\n",
    "                raise Exception(f\"Invalid category id: {catid}\")\n",
    "            for split, imgids in catid_split_imgids[catid].items():\n",
    "                if len(imgids) == 0:\n",
    "                    raise NoInstanceException(\n",
    "                        f\"No image for category {catid} in split {split}\"\n",
    "                    )\n",
    "                split_imgids[split] = split_imgids[split].union(set(imgids))\n",
    "\n",
    "                cat_split_imgids[catid][split] = set(imgids)\n",
    "                if split == \"train\":\n",
    "                    min_train_count = min(len(set(imgids)), min_train_count)\n",
    "\n",
    "        if stratify:\n",
    "            np.random.seed(seed)\n",
    "            for catid, split_imgids_dict in cat_split_imgids.items():\n",
    "                for split, imgids in split_imgids_dict.items():\n",
    "                    if split == \"train\":\n",
    "                        sampled_imgids = set(\n",
    "                            np.random.choice(\n",
    "                                list(imgids), min_train_count, replace=False\n",
    "                            )\n",
    "                        )\n",
    "                    else:\n",
    "                        sampled_imgids = imgids\n",
    "                    split_imgids[split] = split_imgids[split].union(sampled_imgids)\n",
    "\n",
    "        for split, imgids_set in split_imgids.items():\n",
    "            split_img_dir = image_dir / split\n",
    "            split_lab_dir = label_dir / split\n",
    "            split_img_dir.mkdir(parents=True, exist_ok=True)\n",
    "            split_lab_dir.mkdir(parents=True, exist_ok=True)\n",
    "            for imgid in list(imgids_set):\n",
    "                img = self.imgs[imgid]\n",
    "                img_src = Path(img[\"url\"])\n",
    "                img_dst = split_img_dir / img_src.name\n",
    "                assert img_src.is_file()\n",
    "\n",
    "                label = \"\"\n",
    "                for annid in img[\"annotation_ids\"]:\n",
    "                    annotation = self.annotations[annid]\n",
    "                    catid = annotation[\"category_id\"]\n",
    "                    if catid not in target_catids:\n",
    "                        continue\n",
    "                    try:\n",
    "                        bbox = xulyulwh_to_clipped_xcycwh(\n",
    "                            annotation[\"bbox\"], img[\"width\"], img[\"height\"]\n",
    "                        )\n",
    "                        bbox = [\n",
    "                            bbox[0] / img[\"width\"],\n",
    "                            bbox[1] / img[\"height\"],\n",
    "                            bbox[2] / img[\"width\"],\n",
    "                            bbox[3] / img[\"height\"],\n",
    "                        ]\n",
    "                    except Exception:\n",
    "                        continue\n",
    "                    label += \" \".join(\n",
    "                        [\n",
    "                            str(target_catids.index(catid)),\n",
    "                            *[str(coordinate) for coordinate in bbox],\n",
    "                        ]\n",
    "                    )\n",
    "                    label += \"\\n\"\n",
    "                if len(label) < 0:\n",
    "                    continue\n",
    "                with open(split_lab_dir / (img_src.with_suffix(\".txt\").name), \"w\") as f:\n",
    "                    f.write(label)\n",
    "\n",
    "                if not img_dst.exists():\n",
    "                    img_dst.symlink_to(img_src)\n",
    "\n",
    "    def create_ut_yaml(self, target_categories, annotation_root, yaml_path):\n",
    "        content = f\"path: {Path(annotation_root).resolve()}\"\n",
    "        for split in self.group_imgids_by_key(\"split\").keys():\n",
    "            content += f\"\\n{split}: images/{split}\"\n",
    "        content += \"\\n\\nnames:\\n\"\n",
    "        for i, category in enumerate(target_categories):\n",
    "            assert isinstance(category, str)\n",
    "            content += f\"  {i}: {category}\\n\"\n",
    "        with open(yaml_path, \"w\") as f:\n",
    "            f.write(content)\n",
    "\n",
    "\n",
    "class NoInstanceException(Exception):\n",
    "    \"\"\"Exception raised when there is no instance for current condition.\"\"\"\n",
    "\n",
    "\n",
    "VERSION = \"0.1.0\"\n",
    "\n",
    "\n",
    "class EgoObjects(DetectionDataset):\n",
    "    \"\"\"DetectionDataset for EgoObjects dataset (https://ai.meta.com/datasets/egoobjects-downloads/).\n",
    "    The minimal directory structure is as follows:\n",
    "    root/\n",
    "    ├── train.json\n",
    "    ├── eval.json\n",
    "    ├── metadata.json\n",
    "    ├── images/\n",
    "    │   ├── ...\n",
    "    Since EgoObjects dataset is a piecewise video dataset, each image has a group_id, video_id, and frame_id.\n",
    "\n",
    "    Args:\n",
    "        root (str | Path): Root directory of the dataset.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, root: str | Path) -> None:\n",
    "        self.root = Path(root) if not isinstance(root, Path) else root\n",
    "        assert self.root.is_dir()\n",
    "        self.imgs = {}\n",
    "        self.annotations = {}\n",
    "        self.imgid_orders = defaultdict(list)\n",
    "        self.cache_dir = self.root / \".cache\" / VERSION\n",
    "        self.cache_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        with open(self.root / \"metadata.json\") as fp:\n",
    "            metadata = json.load(fp)\n",
    "\n",
    "        if (\n",
    "            (self.cache_dir / \"categories.pkl\").exists()\n",
    "            and (self.cache_dir / \"imgs.pkl\").exists()\n",
    "            and (self.cache_dir / \"annotations.pkl\").exists()\n",
    "            and (self.cache_dir / \"imgid_orders.pkl\").exists()\n",
    "        ):\n",
    "            with open(self.cache_dir / \"categories.pkl\", \"rb\") as fp:\n",
    "                self.categories = pickle.load(fp)\n",
    "            with open(self.cache_dir / \"imgs.pkl\", \"rb\") as fp:\n",
    "                self.imgs = pickle.load(fp)\n",
    "            with open(self.cache_dir / \"annotations.pkl\", \"rb\") as fp:\n",
    "                self.annotations = pickle.load(fp)\n",
    "            with open(self.cache_dir / \"imgid_orders.pkl\", \"rb\") as fp:\n",
    "                self.imgid_orders = pickle.load(fp)\n",
    "            return\n",
    "\n",
    "        self.categories = {\n",
    "            catobj[\"id\"]: {\n",
    "                \"category_id\": catobj[\"id\"],\n",
    "                \"category\": category_names_to_snake_case(catobj[\"name\"]),\n",
    "            }\n",
    "            for catobj in metadata[\"categories\"]\n",
    "        }\n",
    "\n",
    "        for label_file in (\"train\", \"eval\"):\n",
    "            with open(self.root / f\"{label_file}.json\") as fp:\n",
    "                data = json.load(fp)\n",
    "\n",
    "            s_g_v_f_imgid = {}\n",
    "            split = \"train\" if label_file == \"train\" else \"val\"\n",
    "            for img in data[\"images\"]:\n",
    "                url = str((self.root / \"images\" / img[\"url\"]).resolve())\n",
    "                # split = img[\"subset\"] if \"subset\" in img else label_file\n",
    "                # split = \"train\" if label_file == \"train\" else \"val\"\n",
    "                self.imgs[img[\"id\"]] = {\n",
    "                    \"img_id\": img[\"id\"],\n",
    "                    \"url\": url,\n",
    "                    \"width\": img[\"width\"],\n",
    "                    \"height\": img[\"height\"],\n",
    "                    \"annotation_ids\": [],\n",
    "                    \"split\": split,\n",
    "                    \"group_id\": img[\"group_id\"],\n",
    "                    \"video_id\": img[\"video_id\"],\n",
    "                    \"frame_id\": int(img[\"frame_id\"]),\n",
    "                }\n",
    "\n",
    "                if split not in s_g_v_f_imgid:\n",
    "                    s_g_v_f_imgid[split] = {}\n",
    "                if img[\"group_id\"] not in s_g_v_f_imgid[split]:\n",
    "                    s_g_v_f_imgid[split][img[\"group_id\"]] = {}\n",
    "                if img[\"video_id\"] not in s_g_v_f_imgid[split][img[\"group_id\"]]:\n",
    "                    s_g_v_f_imgid[split][img[\"group_id\"]][img[\"video_id\"]] = {}\n",
    "                s_g_v_f_imgid[split][img[\"group_id\"]][img[\"video_id\"]][\n",
    "                    int(img[\"frame_id\"])\n",
    "                ] = img[\"id\"]\n",
    "\n",
    "            for split, g_v_f_imgid in s_g_v_f_imgid.items():\n",
    "                for v_f_imgid in g_v_f_imgid.values():\n",
    "                    v_f_imgid = dict(sorted(v_f_imgid.items()))\n",
    "                    for f_imgid in v_f_imgid.values():\n",
    "                        f_imgid = dict(sorted(f_imgid.items()))\n",
    "                        self.imgid_orders[split] += f_imgid.values()\n",
    "\n",
    "            cat_annotations = {\n",
    "                catid: {\n",
    "                    \"instances\": set(),\n",
    "                    \"areas\": [],\n",
    "                    \"area_ratios\": [],\n",
    "                }\n",
    "                for catid in self.categories.keys()\n",
    "            }\n",
    "\n",
    "            for ann in data[\"annotations\"]:\n",
    "                img = self.imgs[ann[\"image_id\"]]\n",
    "\n",
    "                img[\"annotation_ids\"].append(ann[\"id\"])\n",
    "\n",
    "                catid = ann[\"_category_id\"]\n",
    "                area = ann[\"area\"]\n",
    "                area_ratio = area / (img[\"width\"] * img[\"height\"])\n",
    "                self.annotations[ann[\"id\"]] = {\n",
    "                    \"annotation_id\": ann[\"id\"],\n",
    "                    \"category_id\": catid,\n",
    "                    \"img_id\": ann[\"image_id\"],\n",
    "                    \"bbox\": ann[\"bbox\"],\n",
    "                    \"area\": area,\n",
    "                    \"area_ratio\": area_ratio,\n",
    "                }\n",
    "\n",
    "                cat_annotations[catid][\"instances\"].add(ann[\"instance_tag\"])\n",
    "                cat_annotations[catid][\"areas\"].append(area)\n",
    "                cat_annotations[catid][\"area_ratios\"].append(area_ratio)\n",
    "\n",
    "            for catid, cat_annotation in cat_annotations.items():\n",
    "                self.categories[catid][f\"{split}_instance_count\"] = len(\n",
    "                    cat_annotation[\"instances\"]\n",
    "                )\n",
    "                annot_count = len(cat_annotation[\"areas\"])\n",
    "                self.categories[catid][f\"{split}_annotation_count\"] = annot_count\n",
    "                if annot_count > 1:\n",
    "                    self.categories[catid][f\"{split}_area_mean\"] = mean(\n",
    "                        cat_annotation[\"areas\"]\n",
    "                    )\n",
    "                    self.categories[catid][f\"{split}_area_stdev\"] = stdev(\n",
    "                        cat_annotation[\"areas\"]\n",
    "                    )\n",
    "                    self.categories[catid][f\"{split}_area_ratio_mean\"] = mean(\n",
    "                        cat_annotation[\"area_ratios\"]\n",
    "                    )\n",
    "                    self.categories[catid][f\"{split}_area_ratio_stdev\"] = stdev(\n",
    "                        cat_annotation[\"area_ratios\"]\n",
    "                    )\n",
    "                elif annot_count == 1:\n",
    "                    self.categories[catid][f\"{split}_area_mean\"] = cat_annotation[\n",
    "                        \"areas\"\n",
    "                    ][0]\n",
    "                    self.categories[catid][f\"{split}_area_stdev\"] = 0\n",
    "                    self.categories[catid][f\"{split}_area_ratio_mean\"] = cat_annotation[\n",
    "                        \"area_ratios\"\n",
    "                    ][0]\n",
    "                    self.categories[catid][f\"{split}_area_ratio_stdev\"] = 0\n",
    "                else:\n",
    "                    self.categories[catid][f\"{split}_area_mean\"] = 0\n",
    "                    self.categories[catid][f\"{split}_area_stdev\"] = 0\n",
    "                    self.categories[catid][f\"{split}_area_ratio_mean\"] = 0\n",
    "                    self.categories[catid][f\"{split}_area_ratio_stdev\"] = 0\n",
    "\n",
    "        self.imgid_orders = dict(self.imgid_orders)\n",
    "\n",
    "        with open(self.cache_dir / \"categories.pkl\", \"wb\") as fp:\n",
    "            pickle.dump(self.categories, fp)\n",
    "        with open(self.cache_dir / \"imgs.pkl\", \"wb\") as fp:\n",
    "            pickle.dump(self.imgs, fp)\n",
    "        with open(self.cache_dir / \"annotations.pkl\", \"wb\") as fp:\n",
    "            pickle.dump(self.annotations, fp)\n",
    "        with open(self.cache_dir / \"imgid_orders.pkl\", \"wb\") as fp:\n",
    "            pickle.dump(self.imgid_orders, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = \"/data/projects/multiexpert/EgoObjects\"\n",
    "\n",
    "egoobject_dataset = EgoObjects(root_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "638\n",
      "1665813890465793 {'img_id': 1665813890465793, 'url': '/data/projects/multiexpert/EgoObjects/images/600FAAD73B7D73AB5A896F9253377DBC_04_18.jpg', 'width': 1280, 'height': 720, 'annotation_ids': [252828, 252829, 252830, 252831, 252832], 'split': 'train', 'group_id': '600FAAD73B7D73AB5A896F9253377DBC', 'video_id': '04', 'frame_id': 18}\n",
      "600FAAD73B7D73AB5A896F9253377DBC_04_18.jpg\n",
      "1 {'annotation_id': 1, 'category_id': 235, 'img_id': 2336139953203985, 'bbox': [394.25, 600.07, 599.31, 275.62], 'area': 165181.8222, 'area_ratio': 0.10338751689933504}\n"
     ]
    }
   ],
   "source": [
    "print(len(egoobject_dataset.categories))\n",
    "for key, value in egoobject_dataset.imgs.items():\n",
    "    print(key, value)\n",
    "    file_name = value[\"url\"].split(\"/\")[-1]\n",
    "    print(file_name)\n",
    "    break\n",
    "\n",
    "for key, value in egoobject_dataset.annotations.items():\n",
    "    print(key, value)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "train_json_format =  dict({\n",
    "    \"info\": {\n",
    "        \"description\": \"EgoObjects dataset\"\n",
    "    },\n",
    "    \"licenses\": [\n",
    "        {\n",
    "            \"url\": \"https://ai.meta.com/datasets/egoobjects-downloads/\",\n",
    "            \"id\": 1,\n",
    "            \"name\": \"Meta AI\"\n",
    "        }\n",
    "    ],\n",
    "    \"images\": list(),\n",
    "    \"annotations\": list(),\n",
    "    \"categories\": list()\n",
    "})\n",
    "\n",
    "val_json_format =  dict({\n",
    "    \"info\": {\n",
    "        \"description\": \"EgoObjects dataset\"\n",
    "    },\n",
    "    \"licenses\": [\n",
    "        {\n",
    "            \"url\": \"https://ai.meta.com/datasets/egoobjects-downloads/\",\n",
    "            \"id\": 1,\n",
    "            \"name\": \"Meta AI\"\n",
    "        }\n",
    "    ],\n",
    "    \"images\": list(),\n",
    "    \"annotations\": list(),\n",
    "    \"categories\": list()\n",
    "})\n",
    "\n",
    "## Categories\n",
    "new_categories = list()\n",
    "for key, value in egoobject_dataset.categories.items():\n",
    "    new_categories.append({\n",
    "        \"id\": value[\"category_id\"],\n",
    "        \"name\": value[\"category\"]\n",
    "    })\n",
    "\n",
    "## Images\n",
    "new_images_train = list()\n",
    "new_images_val = list()\n",
    "\n",
    "for key, value in egoobject_dataset.imgs.items():\n",
    "    file_name = value[\"url\"].split(\"/\")[-1]\n",
    "    if value[\"split\"] == \"train\":\n",
    "        new_images_train.append({\n",
    "            \"id\": value[\"img_id\"],\n",
    "            \"url\": value[\"url\"],\n",
    "            \"file_name\": file_name,\n",
    "            \"width\": value[\"width\"],\n",
    "            \"height\": value[\"height\"],\n",
    "            \"split\": value[\"split\"]\n",
    "        })\n",
    "    elif value[\"split\"] == \"val\":\n",
    "        new_images_val.append({\n",
    "            \"id\": value[\"img_id\"],\n",
    "            \"url\": value[\"url\"],\n",
    "            \"file_name\": file_name,\n",
    "            \"width\": value[\"width\"],\n",
    "            \"height\": value[\"height\"],\n",
    "            \"split\": value[\"split\"]\n",
    "        })\n",
    "\n",
    "new_annotations_train = list()\n",
    "new_annotations_val = list()\n",
    "\n",
    "for key, value in egoobject_dataset.annotations.items():\n",
    "    new_annotation = {\n",
    "        \"id\": value[\"annotation_id\"],\n",
    "        \"category_id\": value[\"category_id\"],\n",
    "        \"image_id\": value[\"img_id\"],\n",
    "        \"bbox\": value[\"bbox\"],\n",
    "        \"area\": value[\"area\"],\n",
    "        \"area_ratio\": value[\"area_ratio\"]\n",
    "    }\n",
    "    if egoobject_dataset.imgs[value[\"img_id\"]][\"split\"] == \"train\":\n",
    "        new_annotations_train.append(new_annotation)\n",
    "    elif egoobject_dataset.imgs[value[\"img_id\"]][\"split\"] == \"val\":\n",
    "        new_annotations_val.append(new_annotation)\n",
    "\n",
    "train_json_format[\"categories\"] = new_categories\n",
    "train_json_format[\"images\"] = new_images_train\n",
    "train_json_format[\"annotations\"] = new_annotations_train\n",
    "\n",
    "val_json_format[\"categories\"] = new_categories\n",
    "val_json_format[\"images\"] = new_images_val\n",
    "val_json_format[\"annotations\"] = new_annotations_val\n",
    "\n",
    "annotations_path = \"data/egoobjects/annotations\"\n",
    "os.makedirs(annotations_path, exist_ok=True)\n",
    "\n",
    "with open(os.path.join(annotations_path, \"train.json\"), \"w\") as f:\n",
    "    json.dump(train_json_format, f)\n",
    "\n",
    "with open(os.path.join(annotations_path, \"val.json\"), \"w\") as f:\n",
    "    json.dump(val_json_format, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Linking images\n",
    "import os\n",
    "train_image_path = \"data/egoobjects/images/train\"\n",
    "val_image_path = \"data/egoobjects/images/val\"\n",
    "\n",
    "os.makedirs(train_image_path, exist_ok=True)\n",
    "os.makedirs(val_image_path, exist_ok=True)\n",
    "\n",
    "\n",
    "for key, value in egoobject_dataset.imgs.items():\n",
    "    file_name = value[\"url\"].split(\"/\")[-1]\n",
    "    if value[\"split\"] == \"train\":\n",
    "        os.symlink(value[\"url\"], os.path.join(train_image_path, file_name))\n",
    "    elif value[\"split\"] == \"val\":\n",
    "        os.symlink(value[\"url\"], os.path.join(val_image_path, file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLASSES = ('accordion', 'adhesive_tape', 'air_conditioner', 'air_fryer', 'air_purifier', 'airplane', 'alarm_clock', 'almond', 'alpaca', 'aluminium_foil', 'ambulance', 'ant', 'antelope', 'apple', 'apricot', 'armadillo', 'artichoke', 'arugula', 'avocado', 'axe', 'baby_monitor', 'backpack', 'bacon', 'badminton_birdie', 'badminton_racket', 'bagel', 'balance_beam', 'balloon', 'banana', 'band_aid', 'banjo', 'barge', 'barrel', 'baseball_bat', 'baseball_glove', 'basketball', 'bat_animal', 'bathroom_cabinet', 'bathtub', 'beaker', 'beans', 'bee', 'beef', 'beehive', 'beer', 'bell_pepper', 'belt', 'bench', 'bicycle', 'bicycle_helmet', 'bicycle_wheel', 'bidet', 'billboard', 'billiard_table', 'binoculars', 'blackberry', 'blanket', 'blender', 'blue_jay', 'blueberry', 'bok_choy', 'bomb', 'bonsai', 'book', 'bookcase', 'boot', 'bottle', 'bottle_opener', 'bow_and_arrow', 'bowl', 'bowling_equipment', 'box', 'box_of_macaroni_and_cheese', 'boxing_gloves', 'brassiere', 'bread', 'bridges', 'briefcase', 'broccoli', 'bronze_sculpture', 'brown_bear', 'brussel_sprouts', 'bull', 'burrito', 'bus', 'bust', 'butterfly', 'cabbage', 'cabinetry', 'cake', 'cake_stand', 'calculator', 'calendar', 'camel', 'camera', 'can_opener', 'canary', 'candle', 'candy', 'cannon', 'canoe', 'cantaloupe', 'carrot', 'cart', 'cashew', 'cassette_deck', 'castle', 'cat', 'cat_furniture', 'caterpillar', 'cattle', 'cauliflower', 'ceiling_fan', 'celery', 'cello', 'centipede', 'chainsaw', 'chair', 'chandelier', 'chard', 'cheese', 'cheetah', 'cherry', 'cherry_tomato', 'chest_of_drawers', 'chicken', 'chicken_breast', 'chime', 'chisel', 'chive', 'chopsticks', 'christmas_tree', 'closet', 'coat', 'cocktail', 'cocktail_shaker', 'coconut', 'coffee', 'coffee_cup', 'coffee_table', 'coffeemaker', 'coin', 'collard_green', 'common_fig', 'common_sunflower', 'computer_keyboard', 'computer_monitor', 'computer_mouse', 'condiment', 'convenience_store', 'cookie', 'cooking_spray', 'corded_phone', 'countertop', 'cowboy_hat', 'crab', 'cream', 'creamer', 'crib', 'cricket_ball', 'crocodile', 'croissant', 'crown', 'crutch', 'cucumber', 'cupboard', 'curtain', 'cutting_board', 'dagger', 'deep_fryer', 'deer', 'dental_floss', 'desk', 'detergent', 'diaper', 'dice', 'digital_clock', 'dinosaur', 'dishwasher', 'dog', 'dog_bed', 'doll', 'dolphin', 'door', 'door_handle', 'doughnut', 'dragonfly', 'drawer', 'dress', 'drill_tool', 'drinking_straw', 'drivers_license', 'drum', 'duck', 'dumbbell', 'eagle', 'earrings', 'egg_food', 'eggplant', 'elephant', 'endive', 'envelope', 'eraser', 'face_powder', 'facial_tissue_holder', 'falcon', 'fax', 'fedora', 'filing_cabinet', 'fire', 'fire_alarm', 'fire_hydrant', 'fire_truck', 'firearm', 'fireplace', 'firework', 'fishing_pole', 'flag', 'flashlight', 'floor_lamp', 'flowerpot', 'flute', 'flying_disc', 'food_processor', 'football', 'football_helmet', 'fork', 'fountain', 'fox', 'french_fries', 'french_horn', 'frisée', 'frog', 'fruit_juice', 'frying_pan', 'game_controller_pad', 'garden_asparagus', 'garlic', 'gas_stove', 'gift', 'ginger', 'giraffe', 'glasses', 'glove', 'goat', 'goggles', 'goldfish', 'golf_ball', 'golf_cart', 'gondola', 'goose', 'grape', 'grapefruit', 'grinder', 'ground_chicken', 'ground_turkey', 'guacamole', 'guitar', 'hair_dryer', 'hair_spray', 'hamburger', 'hammer', 'hamster', 'hand_dryer', 'handbag', 'handgun', 'harbor_seal', 'harmonica', 'harp', 'harpsichord', 'headphones', 'heart_rate_monitor', 'heater', 'hedgehog', 'helicopter', 'high_heels', 'hiking_equipment', 'hippopotamus', 'hockey_puck', 'hockey_stick', 'honeycomb', 'honeydew', 'horizontal_bar', 'horse', 'hot_dog', 'house', 'house_car_key', 'houseplant', 'humidifier', 'ice_cream', 'indoor_rower', 'infant_bed', 'ipod', 'isopod', 'jacket', 'jacuzzi', 'jaguar_animal', 'jeans', 'jellyfish', 'jet_ski', 'jug', 'juice', 'juicer', 'kale', 'kangaroo', 'kettle', 'kitchen_and_dining_room_table', 'kite', 'kiwi', 'knife', 'koala', 'lacrosse_ball', 'lacrosse_stick', 'ladder', 'ladle', 'ladybug', 'lamp', 'lamp_shade', 'lantern', 'laptop', 'laptop_charger', 'lavender_plant', 'lemon', 'lemonade', 'leopard', 'lettuce', 'light_bulb', 'light_switch', 'lighthouse', 'lily', 'lime', 'limousine', 'lion', 'lipstick', 'lizard', 'lobster', 'loveseat', 'lynx', 'magpie', 'mango', 'maple', 'maracas', 'measuring_cup', 'mechanical_fan', 'microphone', 'microwave_oven', 'milk', 'miniskirt', 'mirror', 'missile', 'mixer', 'mixing_bowl', 'mobile_phone', 'monkey', 'motorcycle', 'mouse', 'mouthwash', 'muffin', 'mug', 'mule', 'mushroom', 'musical_keyboard', 'mussel', 'nail_construction', 'napkin', 'necklace', 'nectarine', 'night_light', 'nightstand', 'notebook', 'oboe', 'office_building', 'onion', 'orange', 'organ', 'ostrich', 'otter', 'oven', 'owl', 'oyster', 'paddle', 'palm_tree', 'pancake', 'panda', 'papaya', 'paper', 'paper_cutter', 'paper_towel', 'parachute', 'parking_meter', 'parrot', 'parsnip', 'passport', 'pasta', 'pasta_and_noodles', 'pattypan_squash', 'peach', 'peacock', 'pear', 'pen', 'pencil', 'pencil_case', 'pencil_sharpener', 'penguin', 'peppers', 'perfume', 'personal_flotation_device', 'phone_charger', 'piano', 'picnic_basket', 'picture_frame', 'pig', 'pillow', 'pineapple', 'pitcher_container', 'pizza', 'pizza_cutter', 'plastic_bag', 'plate', 'platter', 'playstation', 'plum', 'polar_bear', 'police_car', 'pomegranate', 'pop_tarts', 'popcorn', 'porch', 'porcupine', 'pork', 'post_it', 'poster', 'potato', 'pottery', 'power_plugs_and_sockets', 'prawn', 'pressure_cooker', 'pretzel', 'printer', 'projector', 'pumpkin', 'punching_bag', 'rabbit', 'raccoon', 'radicchio', 'radish', 'raspberry', 'ratchet_device', 'raven', 'rays_and_skates', 'receipt', 'red_panda', 'red_tomato', 'refrigerator', 'remote_control', 'rhinoceros', 'rhubarb', 'rifle', 'ring', 'ring_binder', 'robotic_vacuum', 'rocket', 'roller_skates', 'rose', 'rugby_ball', 'ruler', 'salad', 'salmon', 'salt_and_pepper_shakers', 'sandal', 'saucer', 'sausage', 'saxophone', 'scale', 'scallop', 'scarf', 'scissors', 'scoreboard', 'scorpion', 'screwdriver', 'sea_lion', 'sea_turtle', 'seahorse', 'seat_belt', 'segway', 'semi_truck_truck_with_long_trailer', 'serving_tray', 'sewing_machine', 'shallot', 'shark', 'shaving_cream', 'sheep', 'shelf', 'shirt', 'shorts', 'shotgun', 'shower', 'shrimp', 'sink', 'skateboard', 'ski', 'skull', 'skunk', 'skyscraper', 'slow_cooker', 'snail', 'snake', 'snowboard', 'snowman', 'snowmobile', 'snowplow', 'soap', 'soap_dispenser', 'soccer_ball', 'sock', 'sofa', 'sombrero', 'sound_bar', 'sparrow', 'spatula', 'speaker_stereo_equipment', 'spice_rack', 'spider', 'spinach', 'spoon', 'sports_uniform', 'squid', 'squirrel', 'stairs', 'stapler', 'starfish', 'stationary_bicycle', 'stethoscope', 'stool', 'stop_sign', 'strawberry', 'street_light', 'stretcher', 'studio_couch', 'submarine', 'submarine_sandwich', 'suit', 'suitcase', 'sun_hat', 'sunglasses', 'surfboard', 'sushi', 'swan', 'sweet_potato', 'swim_cap', 'swimming_pool', 'swimwear', 'sword', 'syringe', 'table_tennis_racket', 'tablet_computer', 'taco', 'tangerine', 'tank', 'tap', 'tart', 'taxi', 'tea', 'tea_cup', 'teapot', 'teddy_bear', 'television', 'tennis_ball', 'tennis_racket', 'tent', 'thermostat', 'tiara', 'tick', 'tie', 'tiger', 'tin_can', 'tire', 'toaster', 'toilet', 'toilet_paper', 'tomato', 'toothbrush', 'toothpaste', 'torch', 'tortoise', 'towel', 'tower', 'traffic_light', 'train', 'training_bench', 'trampoline', 'treadmill', 'tree_house', 'tripod', 'trombone', 'truck', 'trumpet', 'turkey', 'turnip', 'umbrella', 'unicycle', 'vacuum', 'van', 'vase', 'vehicle_registration_plate', 'violin', 'volleyball_ball', 'waffle', 'waffle_iron', 'wall_clock', 'wallet', 'wardrobe', 'washing_machine', 'waste_container', 'watch', 'water_glass', 'watermelon', 'whale', 'wheel', 'wheelchair', 'whisk', 'whiteboard', 'willow', 'window', 'window_blind', 'wine', 'wine_glass', 'wine_rack', 'winter_melon', 'wok', 'wood_burning_stove', 'woodpecker', 'worm', 'wrench', 'xbox', 'yoga_mat', 'zebra', 'zucchini', )\n",
      "PALETTE = [(242, 220, 241), (125, 162, 148), (233, 150, 241), (164, 74, 186), (228, 209, 225), (46, 197, 195), (206, 206, 156), (207, 250, 167), (136, 164, 93), (62, 118, 189), (9, 9, 210), (152, 41, 191), (161, 115, 13), (5, 136, 196), (171, 44, 119), (150, 17, 153), (75, 227, 72), (62, 34, 98), (249, 155, 233), (88, 110, 138), (43, 175, 103), (116, 246, 194), (164, 128, 144), (171, 150, 117), (232, 79, 144), (126, 7, 58), (71, 120, 187), (248, 26, 170), (53, 154, 251), (160, 114, 135), (93, 186, 77), (214, 115, 179), (192, 59, 172), (1, 102, 21), (183, 76, 211), (113, 85, 171), (176, 6, 252), (187, 228, 129), (231, 14, 121), (212, 157, 111), (221, 219, 42), (87, 112, 83), (135, 155, 19), (18, 17, 114), (209, 51, 239), (36, 5, 69), (226, 249, 4), (253, 118, 132), (214, 103, 24), (179, 75, 54), (62, 131, 137), (226, 208, 121), (69, 250, 247), (91, 169, 197), (1, 179, 96), (18, 174, 219), (153, 190, 160), (10, 71, 124), (36, 46, 66), (218, 80, 117), (195, 61, 238), (178, 203, 14), (172, 184, 57), (35, 254, 230), (197, 152, 227), (186, 107, 208), (174, 31, 183), (88, 132, 63), (115, 238, 23), (169, 221, 18), (142, 39, 240), (251, 212, 182), (67, 32, 77), (208, 33, 142), (150, 24, 95), (213, 250, 62), (176, 20, 55), (170, 233, 124), (19, 106, 26), (62, 21, 75), (234, 180, 203), (61, 235, 174), (2, 157, 54), (135, 114, 100), (241, 15, 215), (43, 226, 255), (144, 201, 1), (203, 230, 61), (87, 2, 226), (23, 57, 205), (9, 148, 158), (187, 15, 69), (238, 28, 248), (209, 117, 33), (100, 181, 135), (202, 10, 73), (7, 244, 53), (79, 57, 78), (216, 215, 189), (49, 106, 29), (239, 108, 159), (20, 111, 102), (51, 244, 101), (29, 44, 65), (155, 29, 150), (177, 139, 10), (76, 48, 71), (180, 215, 12), (16, 202, 236), (215, 8, 70), (73, 184, 140), (155, 74, 197), (208, 69, 18), (14, 255, 214), (51, 199, 14), (213, 134, 251), (244, 86, 198), (92, 135, 37), (99, 117, 0), (36, 52, 116), (160, 214, 207), (149, 123, 203), (35, 54, 201), (224, 190, 138), (92, 240, 85), (12, 132, 87), (151, 89, 164), (254, 94, 66), (241, 166, 136), (81, 156, 114), (133, 203, 133), (140, 25, 177), (173, 34, 102), (197, 215, 155), (181, 165, 99), (103, 49, 171), (87, 118, 188), (145, 32, 146), (80, 173, 26), (190, 114, 207), (150, 145, 14), (162, 177, 6), (85, 55, 112), (226, 50, 109), (111, 56, 185), (94, 190, 22), (136, 184, 115), (50, 194, 43), (45, 253, 156), (95, 75, 60), (4, 210, 174), (4, 41, 122), (34, 121, 71), (145, 218, 121), (55, 129, 99), (112, 155, 57), (246, 180, 250), (30, 64, 80), (181, 34, 20), (98, 114, 60), (169, 1, 63), (245, 48, 14), (134, 187, 158), (171, 121, 18), (255, 161, 89), (194, 106, 119), (40, 36, 75), (129, 231, 188), (249, 74, 215), (129, 118, 199), (222, 233, 193), (201, 108, 39), (193, 254, 71), (92, 171, 156), (176, 29, 32), (89, 22, 177), (188, 166, 99), (62, 37, 31), (51, 202, 81), (35, 76, 173), (10, 192, 14), (193, 207, 190), (52, 219, 52), (99, 127, 180), (99, 20, 156), (206, 52, 202), (228, 174, 139), (97, 2, 89), (199, 239, 137), (238, 148, 204), (77, 135, 234), (174, 20, 129), (32, 102, 53), (58, 186, 216), (60, 197, 3), (82, 213, 197), (123, 210, 197), (172, 56, 184), (188, 147, 34), (150, 167, 25), (41, 207, 47), (205, 36, 215), (13, 162, 36), (166, 230, 23), (89, 198, 20), (147, 18, 149), (111, 142, 199), (176, 132, 110), (237, 21, 164), (237, 152, 198), (200, 187, 70), (53, 53, 164), (8, 109, 189), (93, 48, 64), (247, 206, 25), (179, 148, 0), (80, 181, 195), (25, 24, 110), (29, 56, 30), (24, 88, 51), (141, 40, 189), (10, 41, 75), (236, 152, 250), (77, 33, 219), (68, 40, 204), (89, 1, 62), (125, 144, 133), (0, 7, 216), (150, 97, 57), (45, 80, 195), (203, 113, 189), (51, 35, 253), (178, 53, 178), (81, 101, 27), (80, 95, 101), (50, 181, 165), (195, 155, 63), (19, 246, 111), (7, 156, 29), (250, 147, 185), (133, 1, 235), (42, 31, 69), (45, 248, 212), (221, 224, 50), (215, 96, 226), (193, 193, 195), (103, 165, 131), (131, 207, 102), (16, 97, 204), (230, 52, 244), (81, 37, 195), (204, 168, 130), (140, 2, 239), (220, 161, 122), (242, 39, 72), (126, 70, 42), (167, 118, 161), (40, 6, 111), (183, 83, 15), (144, 217, 179), (253, 236, 77), (232, 169, 122), (175, 237, 232), (64, 237, 50), (124, 39, 207), (139, 14, 37), (246, 18, 242), (150, 198, 53), (185, 191, 160), (253, 117, 15), (5, 31, 217), (192, 55, 166), (13, 82, 71), (173, 29, 148), (193, 49, 86), (84, 138, 219), (140, 145, 20), (191, 135, 220), (16, 183, 208), (116, 52, 147), (9, 191, 177), (62, 220, 254), (51, 147, 157), (196, 71, 214), (41, 29, 252), (12, 82, 0), (137, 123, 252), (236, 221, 149), (27, 97, 84), (10, 126, 150), (1, 231, 82), (218, 40, 163), (144, 136, 68), (57, 173, 90), (101, 217, 253), (104, 154, 193), (198, 239, 51), (212, 59, 119), (207, 64, 177), (197, 17, 110), (68, 28, 248), (154, 191, 15), (200, 5, 123), (253, 169, 22), (75, 157, 151), (60, 215, 247), (119, 82, 18), (66, 205, 115), (45, 255, 3), (166, 253, 214), (65, 243, 120), (244, 121, 6), (10, 39, 150), (179, 245, 42), (160, 100, 233), (156, 109, 19), (109, 70, 131), (46, 86, 53), (186, 94, 99), (19, 188, 128), (254, 5, 240), (186, 84, 202), (69, 32, 81), (190, 133, 227), (77, 123, 44), (246, 21, 216), (73, 59, 30), (93, 152, 68), (118, 93, 38), (67, 194, 245), (177, 96, 125), (240, 111, 158), (66, 175, 217), (34, 100, 175), (23, 62, 224), (79, 233, 105), (105, 198, 190), (194, 39, 229), (139, 203, 115), (240, 249, 102), (84, 93, 122), (191, 173, 70), (61, 153, 234), (40, 67, 254), (169, 130, 130), (21, 211, 135), (230, 160, 88), (158, 70, 198), (156, 216, 10), (150, 237, 222), (30, 190, 59), (191, 71, 77), (73, 201, 222), (110, 187, 61), (212, 79, 27), (30, 59, 209), (166, 37, 45), (211, 177, 217), (231, 129, 217), (241, 124, 193), (182, 127, 200), (110, 185, 166), (19, 102, 178), (242, 197, 39), (122, 37, 75), (192, 142, 148), (253, 20, 253), (181, 181, 37), (141, 74, 118), (116, 15, 80), (120, 132, 94), (119, 38, 77), (0, 218, 255), (77, 13, 237), (61, 196, 48), (54, 70, 81), (211, 234, 218), (102, 69, 13), (141, 35, 35), (90, 188, 65), (61, 136, 239), (81, 138, 157), (186, 72, 210), (234, 27, 93), (21, 171, 166), (135, 246, 23), (76, 74, 12), (79, 96, 117), (184, 201, 222), (210, 255, 58), (117, 58, 98), (81, 228, 216), (83, 148, 50), (172, 208, 85), (108, 79, 225), (67, 217, 190), (105, 150, 245), (15, 206, 120), (230, 137, 196), (63, 14, 20), (81, 158, 194), (138, 46, 40), (190, 46, 122), (129, 227, 162), (233, 187, 20), (252, 72, 217), (202, 119, 199), (22, 5, 178), (243, 216, 198), (88, 190, 64), (204, 98, 156), (250, 127, 9), (146, 164, 89), (101, 205, 92), (76, 210, 79), (225, 154, 57), (212, 97, 8), (35, 213, 139), (71, 51, 227), (117, 70, 164), (4, 41, 252), (108, 122, 51), (4, 146, 171), (247, 166, 175), (227, 252, 0), (32, 84, 13), (210, 180, 41), (156, 37, 72), (89, 249, 228), (84, 29, 64), (226, 174, 208), (39, 153, 77), (232, 186, 18), (14, 73, 191), (168, 58, 232), (137, 102, 217), (185, 198, 242), (226, 8, 184), (191, 46, 61), (14, 85, 133), (79, 87, 70), (168, 46, 178), (31, 195, 49), (242, 223, 190), (102, 200, 61), (3, 10, 207), (22, 223, 33), (57, 224, 139), (203, 160, 253), (91, 97, 154), (30, 178, 14), (49, 120, 84), (101, 54, 223), (183, 33, 19), (85, 39, 173), (84, 101, 236), (241, 48, 206), (240, 141, 79), (70, 168, 94), (112, 169, 70), (107, 119, 148), (201, 157, 224), (103, 232, 122), (84, 84, 10), (22, 128, 153), (64, 252, 17), (77, 17, 201), (216, 47, 18), (5, 63, 165), (202, 228, 15), (62, 32, 122), (0, 167, 157), (102, 151, 230), (69, 240, 196), (178, 111, 225), (42, 201, 47), (169, 126, 199), (242, 38, 183), (94, 140, 192), (13, 134, 227), (58, 179, 90), (174, 200, 203), (23, 167, 68), (19, 205, 120), (182, 220, 30), (142, 224, 125), (141, 40, 28), (134, 250, 26), (195, 18, 40), (74, 199, 98), (207, 82, 110), (146, 5, 103), (61, 248, 134), (198, 101, 129), (19, 247, 121), (88, 16, 221), (167, 181, 33), (112, 206, 74), (210, 23, 97), (223, 249, 76), (151, 185, 26), (11, 33, 220), (140, 130, 124), (160, 187, 220), (51, 56, 113), (76, 207, 35), (50, 46, 88), (199, 53, 11), (61, 195, 41), (60, 15, 119), (197, 226, 159), (171, 81, 136), (53, 84, 22), (68, 243, 147), (152, 18, 237), (191, 70, 156), (196, 70, 61), (35, 149, 71), (101, 236, 89), (75, 48, 89), (235, 84, 199), (173, 71, 43), (101, 105, 176), (203, 34, 77), (31, 128, 215), (14, 207, 1), (172, 79, 33), (84, 9, 62), (92, 126, 93), (76, 187, 56), (30, 43, 64), (127, 164, 207), (178, 63, 183), (204, 115, 112), (236, 169, 233), (130, 113, 22), (181, 220, 135), (211, 213, 210), (90, 13, 86), (159, 74, 19), (140, 211, 223), (161, 34, 209), (207, 154, 250), (245, 30, 79), (33, 184, 202), (103, 236, 164), (97, 118, 181), (241, 114, 148), (222, 6, 18), (128, 147, 148), (165, 42, 165), (241, 147, 121), (12, 133, 4), (77, 248, 254), (231, 87, 193), (29, 64, 149), (232, 122, 82), (55, 210, 34), (43, 234, 236), (53, 249, 35), (150, 132, 160), (247, 246, 209), (199, 33, 163), (71, 185, 6), (17, 188, 115), (12, 93, 16), (44, 95, 96), (8, 93, 255), (40, 27, 81), (195, 242, 211), (209, 159, 47), (82, 115, 142), (50, 148, 42), (172, 243, 207), (214, 156, 235), (217, 168, 159), (198, 110, 202), (93, 150, 58), (108, 119, 65), (107, 126, 40), (159, 76, 225), (42, 47, 209), (221, 155, 204), (2, 229, 32), (132, 40, 255), (118, 10, 60), (178, 215, 232), (159, 178, 221), (142, 185, 97), (56, 220, 37), (82, 178, 235), (87, 51, 162), (140, 69, 20), (16, 47, 213), (210, 205, 105), (137, 201, 34), (36, 114, 7), (210, 199, 49), (13, 223, 75), (0, 98, 129), (98, 161, 18), (44, 6, 20), (231, 243, 73), (112, 213, 15), (44, 221, 252), (228, 119, 123), (248, 85, 254), (105, 4, 132), (168, 2, 116), (128, 11, 164), (218, 112, 225), (128, 187, 15), (147, 246, 219), (149, 36, 64), (73, 223, 47), (175, 24, 14), (121, 15, 147), (142, 91, 18), (212, 62, 15), (107, 146, 232), (115, 75, 81), (225, 97, 252), (3, 157, 28), (181, 59, 111), (255, 102, 53), (49, 151, 168), (93, 218, 8), (104, 165, 199), (31, 53, 209), (45, 180, 19), (16, 35, 103), (176, 3, 41), (99, 202, 120), (110, 244, 152), (80, 33, 35), (101, 165, 87), (90, 217, 117), (214, 134, 219), ]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "CLASSES = ()\n",
    "PALETTE = []\n",
    "\n",
    "for i in range(len(new_categories)):\n",
    "    CLASSES += (new_categories[i][\"name\"], )\n",
    "    color = (random.randint(0, 255), random.randint(0, 255), random.randint(0, 255))\n",
    "    PALETTE.append(color)\n",
    "\n",
    "CLASSES_str = \"CLASSES = (\"\n",
    "for name in CLASSES:\n",
    "    CLASSES_str += f\"'{name}', \"\n",
    "CLASSES_str += \")\"\n",
    "print(CLASSES_str)\n",
    "\n",
    "PALETTE_str = \"PALETTE = [\"\n",
    "for color in PALETTE:\n",
    "    PALETTE_str += f\"{color}, \"\n",
    "PALETTE_str += \"]\"\n",
    "print(PALETTE_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "annotation_fiel \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
